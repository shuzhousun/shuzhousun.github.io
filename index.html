<html>
<head>
	<meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
	<title>Jinghua Zhang</title>
	<meta content="Jinghua Zhang, shuzhousun.github.io" name="keywords" />
	<style media="screen" type="text/css">html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, font, img, ins, kbd, q, s, samp, small, strike, strong, sub, tt, var, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td {
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}

a {
  color: #1772d0;
  text-decoration:none;
}

a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
}

a.paper {
  font-weight: bold;
  font-size: 12pt;
}

b.paper {
  font-weight: bold;
  font-size: 12pt;
}

* {
  margin: 0pt;
  padding: 0pt;
}

body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 800px;
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  background: #eee;
}

h2 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15pt;
  font-weight: 700;
}

h3 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 16px;
  font-weight: 700;
}

strong {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
  font-weight:bold;
}

ul { 
  list-style: circle;
}

img {
  border: none;
}

li {
  padding-bottom: 0.5em;
  margin-left: 1.4em;
}

alert {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
  font-weight: bold;
  color: #FF0000;
}

em, i {
	font-style:italic;
}

div.section {
  clear: both;
  margin-bottom: 1.5em;
  background: #eee;
}

div.spanner {
  clear: both;
}

div.paper {
  clear: both;
  margin-top: 0.5em;
  margin-bottom: 1em;
  border: 1px solid #ddd;
  background: #fff;
  padding: 1em 1em 1em 1em;
}

div.paper div {
  padding-left: 230px;
}

img.paper {
  margin-bottom: 0.5em;
  float: left;
  width: 200px;
}

span.blurb {
  font-style:italic;
  display:block;
  margin-top:0.75em;
  margin-bottom:0.5em;
}

pre, code {
  font-family: 'Lucida Console', 'Andale Mono', 'Courier', monospaced;
  margin: 1em 0;
  padding: 0;
}

div.paper pre {
  font-size: 0.9em;
}
</style>

<link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css" /><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz' rel='stylesheet' type='text/css'>-->
</head>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-45959174-3', 'wangzheallen.github.io');
  ga('send', 'pageview');

</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-66888300-1', 'auto');
  ga('send', 'pageview');

</script>
<body>
<div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 140px;">
<div style="margin: 0px auto; width: 100%;">
<img title="Jinghua Zhang" style="float: left; padding-left: .01em; height: 140px" src="./jinghua.jpg" />
<div style="padding-left: 9em; vertical-align: top; height: 120px;"><span style="line-height: 150%; font-size: 20pt;">Jinghua Zhang</span><br />
<span><strong>Ph.D. candidate</strong></span><br />
<span>College of Intelligence Science and Technology, <a href="https://www.nudt.edu.cn/">National University of Defense Technology</a>, China</span><br />
<span>Center for Machine Vision and Signal Analysis, <a href="https://www.oulu.fi/en/">University of Oulu</a>, Finland</span><br />
<span><strong>Research Interests</strong>: Deep Learning; Pattern Recognition; Biomedical Image Analysis</span> <br /> 
<span><strong>E-mail</strong>: jinghua.zhang{at}oulu.fi; zjh{at}nudt.edu.cn; zhangjingh{at}foxmail.com</span> <br /> 
</div>
</div>
</div>
<!--<div style="clear: both; background-color: #fff; margin-top: 1.5em; padding: .2em; padding-left: .3em;">-->

<div style="clear: both;">
<div class="section">
<h2>Biography (<a href="CV_Zhang.pdf">CV</a>)</h2>
<div class="paper">

Since September 2021, I have been studying for the Ph.D. degree in Control Science and Engineering at the College of Intelligence Science and Technology of
<a href="https://www.nudt.edu.cn/">National University of Defense Technology (NUDT)</a> under the supervision of <a href="https://www.researchgate.net/profile/Dewen-Hu">Prof. Dewen Hu</a> and <a href="https://scholar.google.com/citations?user=9cMQrVsAAAAJ&hl=en">Prof. Li Liu</a>.
Since November 2022, I have been working as a visiting researcher at the 
 <a href="https://www.oulu.fi/en/university/faculties-and-units/faculty-information-technology-and-electrical-engineering/center-machine-vision-and-signal-analysis">Center for Machine Vision and Signal Analysis</a>, 
 <a href="https://www.oulu.fi/en">University of Oulu</a>, 
 Finland. Before that, I got my B.E. degree in Automation from <a href="https://www.hfuu.edu.cn/">Hefei University (HFU)</a> in 2018, and received my M.E. degree in Biomedical Engineering from <a href="https://www.neu.edu.cn/">Northeastern University (NEU)</a> in 2021 under the supervision of
<a href="https://scholar.google.com/citations?user=pF4AS_EAAAAJ&hl=en">Prof. Chen Li</a>. My research interests include computer vision, pattern recognition, and deep learning.
</div>
</div>
</div>





<div style="clear: both;">
<div class="section">
<!-- <h2 id="confpapers">Publications[<a href="papers.html">More</a>]</h2> -->
<h2 id="confpapers">Publications[<a href="https://scholar.google.com/citations?user=jEkZmuQAAAAJ&hl=en">Google Scholar</a>]</h2>

<div class="paper" id="aire2022"><img class="paper" src="papers/AIRE2022/4.png" title="Applications of artificial neural networks in microorganism image analysis: a comprehensive review from conventional multilayer perceptron to popular convolutional neural network and potential visual transformer" />
  <div> <strong>Applications of artificial neural networks in microorganism image analysis: a comprehensive review from conventional multilayer perceptron to popular convolutional neural network and potential visual transformer</strong><br />
    <ins>Jinghua Zhang</ins>, Chen Li, Yimin Yin, Jiawei Zhang, Marcin Grzegorzek<br />
in <i>Artificial Intelligence Review</i>, 2022.<br />
[<a href="papers/AIRE2022/2022-Artificial Intelligence Review-Applications of artificial neural networks in microorganism.pdf">Paper</a>]
[<a href="papers/AIRE2022/1111.bib">Bibtex</a>]

	  
<br />
  </div>
  <div class="spanner"></div>
  </div>

<div class="paper" id="pr2021"><img class="paper" src="papers/PR2021/LCUNET.png" title="LCU-Net: A Novel Low-cost U-Net for Environmental Microorganism Image Segmentation" />
<div> <strong>LCU-Net: A Novel Low-cost U-Net for Environmental Microorganism Image Segmentation</strong><br />
<ins>Jinghua Zhang</ins>, Chen Li, Sergey Kosov, Marcin Grzegorzek, Kimiaki Shirahama, Tao Jiang, Changhao Sun, Zihan Li, Hong Li <br />
 in <i>Pattern Recognition</i>, 2021 <br />
[<a href='papers/PR2021/2021-Pattern Recognition-LCU-Net for EM Segmentation.pdf'>Paper</a>]
[<a href="papers/PR2021/S0031320321000728.bib">Bibtex</a>]
[<a href="https://github.com/zhang-jinghua/MIaMIA-Open-Codes-LCU-Net">Code</a>]


<br />

</div>
<div class="spanner"></div>
</div>

<div class="paper" id="BMRI2020"><img class="paper" src="papers/BMRI2020/overview.jpg" title="A Multiscale CNN-CRF Framework for Environmental Microorganism Image Segmentation" />
  <div> <strong>A Multiscale CNN-CRF Framework for Environmental Microorganism Image Segmentation</strong><br />
  <ins>Jinghua Zhang</ins>, Chen Li, Frank Kulwa, Xin Zhao, Changhao Sun, Zihan Li, Tao Jiang, Hong Li, Shouliang Qi <br />
   in <i>BioMed Research International</i>, 2020 <br />
  [<a href='papers/BMRI2020/2020-BioMed Research International-A Multiscale CNN-CRF Framework for Environmental Microorganism Image Segmentation.pdf'>Paper</a>]
  [<a href="papers/BMRI2020/555.bib">Bibtex</a>]
  [<a href="https://github.com/zhang-jinghua/MIaMIA-Open-Codes-CNN-CRF">Code</a>]
  
  
  <br />
  
  </div>
  <div class="spanner"></div>
  </div>
	


	



<!-- <div class="paper" id="icmi2019"><img class="paper" src="contests/EmotiW2019/EmotiW2019.jpg" title="Bi-modality Fusion for Emotion Recognition in the Wild" />
  <div> <strong>Bi-modality Fusion for Emotion Recognition in the Wild</strong><br />
    Sunan Li, Wenming Zheng, Yuan Zong, Cheng Lu, Chuangao Tang, Xingxun Jiang, Jiateng Liu, Wanchuang Xia <br />
  in The 21th ACM International Conference on Multimodal Interaction (ACM ICMI),2019. <br />
  [<a href='contests/EmotiW2019/EmotiW2019.pdf'>Paper</a>] 
  [<a href="contests/EmotiW2019/EmotiW2019.bib">Bibtex</a>]
  [<a href="contests/EmotiW2019/EmotiW2019_certificate.pdf">EmotiW2019 Champion</a>]  <br />   
  <alert>Obtain The Champion of the Audio-Video based Emotion Recognition Challenge of the 7th EmotiW Challenge(2019)</alert><br />
  </div>
  <div class="spanner"></div>
  </div>


<div class="paper" id="zhang_AFM"><img class="paper" src="papers/zhang_AFM/zhang_AFM.jpg" title="Attentional focus modulates automatic fnger‑tapping movements" />
<div> <strong>Attentional Focus Modulates Automatic Finger‑tapping Movements</strong><br />
Xilei Zhang, Xingxun Jiang, Xiangyong Yuan, Wenming Zheng <br />
in Scientific Reports, 2021 <br />
[<a href='papers/zhang_AFM/zhang_AFM.pdf'>Paper</a>]
[<a href="papers/zhang_AFM/zhang_AFM.bib">Bibtex</a>]   
[<a href="https://github.com/jiangxingxun/AFM">Code</a>]<br /><br />
<alert>These findings demonstrate compelling evidence that attention can modulate automatic movements and provide an empirical foundation for theories based on such modulation in controlling human behavior. </alert>
</div>
<div class="spanner"></div>
</div> -->

<!--
<div class="paper" id="xia_MADTN"><img class="paper" src="papers/xia_MADTN/xia_MADTN.png" title="Motion Attention Deep Transfer Network for Cross-Database Micro-Expression Recognition" />
  <div> <strong>Motion Attention Deep Transfer Network for Cross-Database Micro-Expression Recognition</strong><br />
Wanchuang Xia, Wenming Zheng, Yuan Zong, Xingxun Jiang<br />
in ICPR workshop on Facial and Body Expressions, micro-expressions and behavior recognition (FBE2020)<br />
[<a href="papers/xia_MADTN/xia_MADTN.pdf">Paper</a>/<a href="papers/xia_MADTN/xia_MADTN_CN.pdf">中文版</a>]
[<a href="papers/xia_MADTN/xia_MADTN.bib">Bibtex</a>]  <br /> 
  </div>
  <div class="spanner"></div>
  </div>
-->


</div>
</div>


	
	




<div style="clear: both;">
  <div class="section">
  <h2 id="confpapers">Academic Service</h2>
  <div class="paper">
  Reviewer of IEEE Transactions on Circuits and Systems for Video Technology<br/ >
  Reviewer of IEEE International Conference on Multimedia & Expo<br/ >
  
    
  <div class="spanner"></div>
  </div>
  </div>
  </div>



<div style="clear: both;">
<div class="section"><h2>Address</h2>
<div class="paper">
  Center for Machine Vision and Signal Analysis, P.O.Box 4500 FI-90014 University of Oulu, Finland.
</div>
</div>
</div>

<div style="clear: both;">
<div class="clustrmapsection">
	<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=efe7e7&w=400&t=tt&d=SuLyV4Xva0JUNvsyOXixmlE2AQ-eoOTvUGmnHsFCjjo&co=548dce&cmo=3acc3a&cmn=ff5353&ct=fcfcfc"></script>
<!-- 	<script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=SuLyV4Xva0JUNvsyOXixmlE2AQ-eoOTvUGmnHsFCjjo"></script> -->
</div>
</div>

<div style="clear:both;">
<p align="right"><font size="2"><a href="https://shuzhousun.github.io/">Updated on Jan. 25, 2023.</a></font></p>
</div>
	
</body>
</html>
